
# ai/app/services/engine_anomaly_service.py
"""
ì—”ì§„ë£¸ ì´ìƒ ì •ë°€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (Engine Anomaly Pipeline)

[íŒŒì¼ ì„¤ëª…]
ì´ íŒŒì¼ì€ ì—”ì§„ë£¸ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë¶€í’ˆë³„ ê²°í•¨ì„ íƒì§€í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
YOLOë¡œ 26ì¢… ë¶€í’ˆì„ ê°ì§€í•˜ê³ , PatchCoreë¡œ ì´ìƒì„ íƒì§€í•œ í›„, LLMìœ¼ë¡œ ê²°í•¨ì„ í•´ì„í•©ë‹ˆë‹¤.

[API ì‘ë‹µ í˜•ì‹]
{
  "status": "WARNING",
  "analysis_type": "SCENE_ENGINE",
  "category": "ENGINE_ROOM",
  "data": { vehicle_type, parts_detected, anomalies_found, results[] }
}
"""
import httpx
import uuid
import asyncio
import io
import base64
import filetype
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urlparse
from PIL import Image
from dataclasses import dataclass, asdict
import json
import os

from ai.app.services.engine_yolo_service import run_yolo_inference
from ai.app.services.crop_service import crop_detected_parts
from ai.app.services.anomaly_service import AnomalyDetector
from ai.app.services.heatmap_service import generate_heatmap_overlay
from ai.app.services.llm_service import suggest_anomaly_label_with_base64, analyze_general_image
from ai.app.schemas.visual_schema import VisualResponse

# =============================================================================
# Configuration
# =============================================================================
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
IMAGE_PIXEL_LIMIT = 100_000_000   # 100M Pixels
Image.MAX_IMAGE_PIXELS = IMAGE_PIXEL_LIMIT

SEMAPHORE = asyncio.Semaphore(5)  # Concurrency Limit
HTTP_TIMEOUT = 30.0  # seconds

# =============================================================================
# Reliability Thresholds
# =============================================================================
FAST_PATH_THRESHOLD = 0.9  # 90% í™•ì‹ í•  ë•Œë§Œ LLM ìŠ¤í‚µ

# EV Parts Definition
EV_PARTS = {
    "Inverter", "Electric_Motor", "Charging_Port", 
    "Inverter_Coolant_Reservoir", "Secondary_Coolant_Reservoir"
}

# =============================================================================
# Result Dataclass
# =============================================================================
@dataclass
class PartAnalysisResult:
    """ë‹¨ì¼ ë¶€í’ˆ ë¶„ì„ ê²°ê³¼"""
    part_name: str
    bbox: List[int]
    confidence: float
    is_anomaly: bool
    anomaly_score: float
    threshold: float
    defect_label: str
    defect_category: str
    description: str
    severity: str
    recommended_action: str
    heatmap_base64: Optional[str] = None


# =============================================================================
# URL Validation (SSRF ë°©ì§€)
# =============================================================================
# validate_s3_url ì œê±° (visual_serviceì—ì„œ í†µí•© ê´€ë¦¬)


# =============================================================================
# Main Pipeline
# =============================================================================
class EngineAnomalyPipeline:
    """
    ì—”ì§„ë£¸ ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸
    - ë¹„ë™ê¸° I/O (httpx)
    - SSRF ë°©ì§€ (URL ê²€ì¦)
    - ê²°ê³¼ëŠ” JSONìœ¼ë¡œ ë°˜í™˜ (S3 ì—…ë¡œë“œ ì—†ìŒ)
    """
    
    def __init__(self, anomaly_detector: Optional[AnomalyDetector] = None):
        if anomaly_detector:
            self.anomaly_detector = anomaly_detector
        else:
            self.anomaly_detector = AnomalyDetector()

    async def analyze(
        self, 
        s3_url: str, 
        image: Optional[Image.Image] = None,
        image_bytes: Optional[bytes] = None,
        yolo_model=None
    ) -> Dict[str, Any]:
        """
        ì—”ì§„ ì´ë¯¸ì§€ ë¶„ì„ (ë©”ì¸ ì§„ì…ì )
        
        Args:
            s3_url: S3 URL (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ ë° ë¡œê¹…ìš©)
            image: ë¯¸ë¦¬ ë¡œë“œëœ PIL Image (ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ ë°©ì§€)
            image_bytes: ë¯¸ë¦¬ ë¡œë“œëœ ì´ë¯¸ì§€ ë°”ì´íŠ¸ (ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ ë°©ì§€)
            yolo_model: YOLO ëª¨ë¸
        """
        request_id = str(uuid.uuid4())[:8]
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ (ì „ë‹¬ë°›ì€ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ - visual_serviceì—ì„œ ë¯¸ë¦¬ ë¡œë“œë˜ì–´ì•¼ í•¨)
        if image is None or image_bytes is None:
             # í•˜ìœ„ í˜¸í™˜ì„± ìœ„í•´ ë¡œë“œ ì‹œë„í•˜ë˜, ê°€ê¸‰ì  visual_service ì‚¬ìš© ê¶Œì¥
             from ai.app.services.visual_service import _safe_load_image
             try:
                 image, image_bytes = await _safe_load_image(s3_url)
             except Exception as e:
                 return {"status": "ERROR", "message": f"Image load failed: {e}", "request_id": request_id}

        # 2. YOLO ì¶”ë¡ 
        yolo_result = await run_yolo_inference(s3_url, image=image, model=yolo_model)
        
        # =================================================================
        # Path B: YOLOê°€ ë¶€í’ˆì„ ê°ì§€í•˜ì§€ ëª»í•œ ê²½ìš°
        # =================================================================
        if yolo_result.detected_count == 0:
            print(f"[Pipeline] Path B: No parts detected. LLM Fallback.")
            llm_result = await analyze_general_image(s3_url)
            
            # API ëª…ì„¸ì„œ í˜•ì‹ì— ë§ì¶¤
            # [ë³´ì • ë¡œì§] Routerê°€ ì—”ì§„ë£¸ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜í–ˆì§€ë§Œ LLMì´ ê³„ê¸°íŒìœ¼ë¡œ íŒë‹¨í•œ ê²½ìš°
            if hasattr(llm_result, "category") and llm_result.category == "DASHBOARD":
                print("[Engine Pipeline] ğŸ’¡ Router Miss detected! Redirecting to Dashboard analysis...")
                from ai.app.services.dashboard_service import analyze_dashboard_image
                return await analyze_dashboard_image(image, s3_url, yolo_model=None)
            
            # [NEW] ë§Œì•½ ìƒíƒœê°€ WARNING/CRITICALì¸ë° resultsê°€ ë¹„ì–´ìˆë‹¤ë©´, LLMì—ê²Œ ê°•ì œë¡œ ë¼ë²¨ë§ì„ ìš”ì²­
            fallback_results = []
            status = llm_result.status if hasattr(llm_result, 'status') else "ERROR"
            
            if status in ["WARNING", "CRITICAL"]:
                print(f"[Engine] YOLO Miss detected (Status: {status}). Requesting LLM Labeling...")
                from ai.app.services.llm_service import generate_training_labels
                label_result = await generate_training_labels(s3_url, "engine")
                
                for lbl in label_result.get("labels", []):
                    # LLM ë¼ë²¨ì„ PartAnalysisResult (dict) í¬ë§·ìœ¼ë¡œ ë³€í™˜
                    fallback_results.append({
                        "part_name": lbl.get("class", "Unknown"),
                        "bbox": lbl.get("bbox", [0,0,0,0]),
                        "confidence": 0.9,
                        "is_anomaly": True,
                        "anomaly_score": 1.0, # LLMì´ ì´ìƒí•˜ë‹¤ê³  í–ˆìœ¼ë¯€ë¡œ ë†’ê²Œ ì„¤ì •
                        "threshold": 0.5,
                        "defect_label": "Anomaly(LLM)",
                        "defect_category": "UNKNOWN",
                        "description": "AI ì •ë°€ ë¶„ì„ìœ¼ë¡œ ì´ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                        "severity": status,
                        "recommended_action": "ì •ë¹„ì†Œ ì ê²€ ê¶Œì¥",
                        "heatmap_base64": None
                    })

            return {
                "status": status,
                "analysis_type": "SCENE_ENGINE",
                "category": "ENGINE_ROOM",
                "data": {
                    "vehicle_type": None,
                    "parts_detected": len(fallback_results),
                    "anomalies_found": len([r for r in fallback_results if r["is_anomaly"]]),
                    "results": fallback_results,
                    "llm_fallback": True,
                    "description": "ì´ë¯¸ì§€ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì—”ì§„ë£¸ ë¶€í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©°, AI ì •ë°€ ë¶„ì„(GPT) ì„œë²„ì™€ ì—°ê²°ë„ ì›í™œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." if status == "ERROR" else (llm_result.data.get("description") if hasattr(llm_result, 'data') else "ì—”ì§„ë£¸ ë¶„ì„ ì‹¤íŒ¨"),
                    "recommendation": "ë°ì€ ê³³ì—ì„œ ì—”ì§„ë£¸ ì „ì²´ê°€ ì˜ ë³´ì´ë„ë¡ ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”." if status == "ERROR" else (llm_result.data.get("recommendation") if hasattr(llm_result, 'data') else "ì •ë¹„ì†Œ ì ê²€ ê¶Œì¥")
                }
            }

        # =================================================================
        # Path A: ì •ë°€ ë¶„ì„
        # =================================================================
        detected_labels = [d.label for d in yolo_result.detections]
        is_ev = any(part in EV_PARTS for part in detected_labels)
        vehicle_type = "EV" if is_ev else "ICE"
        
        # ë¶€í’ˆ í¬ë¡­
        crops = await crop_detected_parts(image_bytes, yolo_result.detections)
        
        # =================================================================
        # ê° ë¶€í’ˆë³„ ë¶„ì„ ìˆ˜í–‰ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ)
        # =================================================================
        # [ì¤‘ìš”] s3_urlì„ ê° ë¶€í’ˆ ë¶„ì„ í•¨ìˆ˜ì— ì „ë‹¬í•´ì•¼ í•¨
        # â†’ Active Learning ì‹œ S3ì— ë¼ë²¨ ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ íŒŒì¼ëª… ìƒì„±ì— í•„ìš”
        # =================================================================
        tasks = []
        for i, (part_name, (crop_img, bbox)) in enumerate(crops.items()):
            # YOLO confidence ì „ë‹¬
            conf = yolo_result.detections[i].confidence if i < len(yolo_result.detections) else 0.0
            tasks.append(
                # [ìˆ˜ì •] s3_url íŒŒë¼ë¯¸í„° ì¶”ê°€í•˜ì—¬ Active Learningì—ì„œ íŒŒì¼ ê²½ë¡œ ìƒì„± ê°€ëŠ¥
                self._analyze_single_part(part_name, crop_img, bbox, conf, request_id, s3_url)
            )
        
        part_results = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ ì§‘ê³„
        results = []
        anomaly_count = 0
        for res in part_results:
            if res:
                results.append(asdict(res))
                if res.is_anomaly:
                    anomaly_count += 1

        # ìµœì¢… ìƒíƒœ ê²°ì •: ì´ìƒì´ ìˆìœ¼ë©´ WARNING, CRITICAL íŒì •
        final_status = "NORMAL"
        for res in results:
            if res.get("severity") == "CRITICAL":
                final_status = "CRITICAL"
                break
            elif res.get("is_anomaly") or res.get("severity") == "WARNING":
                final_status = "WARNING"
        
        # API ëª…ì„¸ì„œ í˜•ì‹ì— ë§ì¶¤
        return {
            "status": final_status,
            "analysis_type": "SCENE_ENGINE",
            "category": "ENGINE_ROOM",
            "data": {
                "vehicle_type": vehicle_type,
                "parts_detected": len(results),
                "anomalies_found": anomaly_count,
                "results": results
            }
        }

    async def _analyze_single_part(
        self, 
        part_name: str, 
        crop_img: Image.Image, 
        bbox: List[int],
        confidence: float,
        request_id: str,
        s3_url: str  # [ì¶”ê°€] Active Learning S3 ì €ì¥ ì‹œ íŒŒì¼ëª… ìƒì„±ì— í•„ìš”
    ) -> PartAnalysisResult:
        """
        ë‹¨ì¼ ë¶€í’ˆ ì´ìƒ íƒì§€
        
        [íŒŒë¼ë¯¸í„° ì„¤ëª…]
        - s3_url: ì›ë³¸ ì´ë¯¸ì§€ì˜ S3 ê²½ë¡œ. Active Learning ì‹œ ë¼ë²¨ JSON ì €ì¥ ê²½ë¡œ ìƒì„±ì— ì‚¬ìš©.
                  ì˜ˆ: s3://bucket/images/abc123.jpg â†’ dataset/engine/llm_confirmed/abc123_Battery.json
        """
        async with SEMAPHORE:
            # Anomaly Detection
            anomaly_result = await self.anomaly_detector.detect(crop_img, part_name)
            
            heatmap_b64 = None
            
            if anomaly_result.is_anomaly:
                # [Dual-Check] ì´ìƒ ë°œê²¬ ì‹œ ë¬´ì¡°ê±´ LLM í˜¸ì¶œ
                heatmap_b64 = None
                try:
                    # íˆíŠ¸ë§µ ìƒì„± (PatchCore í•™ìŠµ ì „ì´ë©´ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬)
                    if anomaly_result.heatmap is not None:
                        heatmap_overlay = generate_heatmap_overlay(crop_img, anomaly_result.heatmap)
                        heatmap_b64 = self._image_to_base64(heatmap_overlay)
                except Exception as e:
                    print(f"[Engine Warning] Heatmap generation failed (Model might be untrained): {e}")
                    heatmap_b64 = None
                
                # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜
                crop_b64 = self._image_to_base64(crop_img)
                
                # LLMì—ê²Œ Base64 + Heatmap(Optional) + BBox ì •ë³´ ì „ë‹¬ (Robust Hybrid)
                llm_res = await suggest_anomaly_label_with_base64(
                    crop_base64=crop_b64,
                    heatmap_base64=heatmap_b64, # ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ None
                    bbox=bbox,                  # BBoxëŠ” í•­ìƒ ì‚¬ìš©
                    part_name=part_name,
                    anomaly_score=anomaly_result.score
                )

                # [ìˆ˜ì •] Dual-Check: Anomaly Detectorê°€ ì´ìƒì„ ê°ì§€í–ˆë”ë¼ë„, 
                # LLMì´ ì •ë°€ ë¶„ì„ í›„ "ì •ìƒ(NORMAL)"ì´ë¼ê³  íŒë‹¨í•˜ë©´ ì´ë¥¼ ì¡´ì¤‘í•©ë‹ˆë‹¤. (False Positive ë°©ì§€)
                if llm_res.get("defect_category") == "NORMAL" or llm_res.get("severity") == "NORMAL":
                     print(f"[Engine] Anomaly Detector flagged issue, but LLM classified as NORMAL. Trusting LLM.")
                     # LLM ê²°ê³¼ ê·¸ëŒ€ë¡œ ìœ ì§€ (NORMAL)
                     pass
                else:
                     # LLMë„ ì´ìƒ ë™ì˜ ì‹œ
                     pass
                
                # [Active Learning] ì—”ì§„ë£¸ ì´ìƒíƒì§€ ì •ë‹µ(Oracle) S3 ì €ì¥
                try:
                    import boto3
                    s3 = boto3.client('s3')
                    bucket = os.getenv("S3_BUCKET_NAME", "car-sentry-data")
                    # ë¶€í’ˆë³„ ê³ ìœ  ID ìƒì„± (ì´ë¯¸ì§€ID + ë¶€í’ˆëª…)
                    # íŒŒì¼ ID ì¶”ì¶œ: s3_urlì´ base64ì¸ ê²½ìš° ì²˜ë¦¬
                    if s3_url.startswith("data:"):
                        import hashlib
                        file_id = hashlib.md5(s3_url.encode()).hexdigest()[:10]
                    else:
                        file_id = os.path.basename(s3_url).split('.')[0]
                        
                    label_key = f"dataset/engine/llm_confirmed/{file_id}_{part_name}.json"
                    
                    oracle_data = {
                        "domain": "engine",
                        "source_url": s3_url,
                        "part_name": part_name,
                        "bbox": bbox,
                        "labels": [{"class": part_name, "bbox": bbox}], # YOLO ì¬í•™ìŠµìš©
                        "anomaly_label": llm_res.get("defect_label"),   # Anomaly ë¶„ë¥˜ ì¬í•™ìŠµìš©
                        "status": llm_res.get("severity")
                    }
                    
                    s3.put_object(
                        Bucket=bucket,
                        Key=label_key,
                        Body=json.dumps(oracle_data, ensure_ascii=False, indent=2),
                        ContentType='application/json'
                    )
                    print(f"[Active Learning] ì—”ì§„ ë¶€í’ˆ ì •ë‹µì§€ ì €ì¥ ì™„ë£Œ: {label_key}")
                except Exception as e:
                    print(f"[Active Learning Engine] ì €ì¥ ì‹¤íŒ¨: {e}")

            else:
                # [Fast Path] ì •ìƒì´ê³  í™•ì‹ ë„ê°€ ë†’ìœ¼ë©´(Scoreê°€ ë§¤ìš° ë‚®ìœ¼ë©´) LLM ìŠ¤í‚µ
                # Confidence = 1.0 - (score / threshold) ë¡œ ê·¼ì‚¬ì¹˜ ê³„ì‚°
                normal_confidence = 1.0 - (anomaly_result.score / anomaly_result.threshold) if anomaly_result.threshold > 0 else 1.0
                
                if normal_confidence >= FAST_PATH_THRESHOLD:
                    print(f"[Engine] Fast Path ì ìš©: {part_name} (Normal Confidence: {normal_confidence:.2f})")
                    llm_res = {
                        "defect_category": "NORMAL",
                        "defect_label": "Normal",
                        "description_ko": f"{part_name} ë¶€í’ˆì´ ì •ìƒì ì¸ ìƒíƒœì…ë‹ˆë‹¤. íŠ¹ë³„í•œ ê²°í•¨ ì§•í›„ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                        "severity": "NORMAL",
                        "recommended_action": "ì£¼ê¸°ì ì¸ ìœ¡ì•ˆ ì ê²€ì„ ìœ ì§€í•˜ì‹­ì‹œì˜¤."
                    }
                else:
                    # ì •ìƒ ë²”ìœ„ì§€ë§Œ í™•ì‹ ë„ê°€ ë‚®ìœ¼ë©´ LLM í™•ì¸ (Dual-Check)
                    print(f"[Engine] ë‚®ì€ í™•ì‹ ë„ ì •ìƒ({normal_confidence:.2f}), LLM í™•ì¸ ìš”ì²­: {part_name}")
                    crop_b64 = self._image_to_base64(crop_img)
                    llm_res = await suggest_anomaly_label_with_base64(
                        crop_base64=crop_b64,
                        heatmap_base64=None, # ì •ìƒì¼ ë• íˆíŠ¸ë§µ ìƒëµ ê°€ëŠ¥
                        bbox=bbox,           # BBoxëŠ” í•­ìƒ ì‚¬ìš©
                        part_name=part_name,
                        anomaly_score=anomaly_result.score
                    )

            return PartAnalysisResult(
                part_name=part_name,
                bbox=bbox,
                confidence=confidence,
                is_anomaly=anomaly_result.is_anomaly,
                anomaly_score=anomaly_result.score,
                threshold=anomaly_result.threshold,
                defect_label=llm_res.get("defect_label", "Unknown"),
                defect_category=llm_res.get("defect_category", "UNKNOWN"),
                description=llm_res.get("description_ko", ""),
                severity=llm_res.get("severity", "WARNING"),
                recommended_action=llm_res.get("recommended_action", ""),
                heatmap_base64=heatmap_b64
            )

    # _load_image_async ì œê±° (visual_service í”¼ì³ í™œìš©)

    def _image_to_base64(self, image: Image.Image, format: str = "JPEG") -> str:
        """PIL Imageë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜ (RGB ë³€í™˜ ë° JPEG í¬í•© ë³´ì¥)"""
        buffer = io.BytesIO()
        # RGBA ë“±ì„ RGBë¡œ ë³€í™˜ (OpenAI JPEG í˜¸í™˜ì„±)
        if image.mode != "RGB":
            image = image.convert("RGB")
        image.save(buffer, format=format, quality=85)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')

    async def close(self):
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ (í•„ìš”ì‹œ)"""
        pass
