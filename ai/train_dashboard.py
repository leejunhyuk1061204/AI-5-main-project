#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Dashboard Warning Light Training Script (YOLOv8)
Usage:
    python train_dashboard.py --mode baseline  # ì´ˆê¸° ëª¨ë¸ ì •ë°€ë„ë§Œ ì¸¡ì •
    python train_dashboard.py --mode train     # í•™ìŠµë§Œ ì‹¤í–‰
    python train_dashboard.py --mode test      # ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸ë§Œ
    python train_dashboard.py --mode all       # ì „ì²´ ì‹¤í–‰ (ê¸°ë³¸ê°’)
"""
import argparse
import os
import boto3
import shutil
import glob
import random
# from roboflow import Roboflow  # ë¡œì»¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
from ultralytics import YOLO

# =============================================================================
# [ì„¤ì •] ê²½ë¡œ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# =============================================================================
ROBOFLOW_API_KEY = os.getenv("ROBOFLOW_API_KEY", "rshw91xj9lAScwI4FBXA")
ROBOFLOW_WORKSPACE = "teamdata"
ROBOFLOW_PROJECT = "car-dashboard-sndt9"
ROBOFLOW_VERSION = 3

BASE_MODEL = "yolov8n.pt"  # ê¸°ë³¸ ì‚¬ì „í•™ìŠµ ëª¨ë¸
OUTPUT_DIR = "ai/runs/dashboard_model"
SAVE_PATH = "ai/weights/dashboard/best.pt"

# ì „ì—­ ë³€ìˆ˜
data_yaml_path = None

# =============================================================================
# 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
# =============================================================================
def download_data():
    global data_yaml_path
    
    print("\n" + "="*50)
    print("[Step 1] ë¡œì»¬ ë°ì´í„°ì…‹ ì¤€ë¹„...")
    print("="*50)
    
    # =============================================================================
    # ë¡œì»¬ ë°ì´í„° í´ë” êµ¬ì¡° (YOLO í‘œì¤€ í˜•ì‹):
    #   ai/data/yolo/
    #     â”œâ”€â”€ train/
    #     â”‚    â”œâ”€â”€ images/    (.jpg íŒŒì¼ë“¤)
    #     â”‚    â””â”€â”€ labels/    (.txt ë¼ë²¨ íŒŒì¼ë“¤)
    #     â”œâ”€â”€ valid/
    #     â”‚    â”œâ”€â”€ images/
    #     â”‚    â””â”€â”€ labels/
    #     â””â”€â”€ data.yaml       (í´ë˜ìŠ¤ ì •ì˜ íŒŒì¼)
    # =============================================================================
    LOCAL_DATA_DIR = "./ai/data/yolo"
    
    # data.yaml ê²½ë¡œ í™•ì¸
    data_yaml_path = os.path.join(LOCAL_DATA_DIR, "data.yaml")
    
    if not os.path.exists(data_yaml_path):
        # í´ë” êµ¬ì¡° ìë™ ìƒì„±
        os.makedirs(os.path.join(LOCAL_DATA_DIR, "train", "images"), exist_ok=True)
        os.makedirs(os.path.join(LOCAL_DATA_DIR, "train", "labels"), exist_ok=True)
        os.makedirs(os.path.join(LOCAL_DATA_DIR, "valid", "images"), exist_ok=True)
        os.makedirs(os.path.join(LOCAL_DATA_DIR, "valid", "labels"), exist_ok=True)
        
        # ê¸°ë³¸ data.yaml ìƒì„±
        default_yaml = """# Car-Sentry YOLO Dataset Configuration
path: ./ai/data/yolo
train: train/images
val: valid/images

# í´ë˜ìŠ¤ ëª©ë¡ (ê²½ê³ ë“±ë§Œ ìš°ì„ )
names:
  0: engine_warning
  1: oil_pressure
  2: battery
  3: tire_pressure
  4: abs_brake
"""
        with open(data_yaml_path, "w", encoding="utf-8") as f:
            f.write(default_yaml)
        
        print(f"[Warning] ë°ì´í„° í´ë”ê°€ ì—†ì–´ì„œ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {LOCAL_DATA_DIR}")
        print(f"         train/images, train/labelsì— ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        print(f"         data.yaml íŒŒì¼ì˜ í´ë˜ìŠ¤ ëª©ë¡ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
        
    print(f"[âœ“] ë°ì´í„° í´ë” í™•ì¸ ì™„ë£Œ: {LOCAL_DATA_DIR}")
    print(f"[âœ“] data.yaml ê²½ë¡œ: {data_yaml_path}")
    
    # (ì„ íƒì ) S3 ìˆ˜ì§‘ ë°ì´í„° ì¶”ê°€ ë³‘í•© - ë‚˜ì¤‘ì— Active Learning ë•Œ ì‚¬ìš©
    load_s3_visual_data(LOCAL_DATA_DIR)
    
    return LOCAL_DATA_DIR

def load_s3_visual_data(dataset_dir):
    """S3ì—ì„œ ìˆ˜ì§‘ëœ ì‹œê° ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í•™ìŠµ ë°ì´í„°ì…‹ì— ë³‘í•©í•©ë‹ˆë‹¤."""
    print("\n[Active Learning] S3 ìˆ˜ì§‘ ë°ì´í„° ë³‘í•© ì‹œë„...")
    
    try:
        s3 = boto3.client('s3')
        bucket_name = os.getenv("S3_BUCKET_NAME", "car-sentry-data")
        prefix = "dataset/visual/DASHBOARD/"
        
        # 1. íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
        if 'Contents' not in objects:
            print("[Info] S3ì— ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 2. ì´ë¯¸ì§€ì™€ ë¼ë²¨ ìŒ ì°¾ê¸°
        files = set()
        for obj in objects['Contents']:
            files.add(obj['Key'])
            
        valid_pairs = []
        for f in files:
            if f.endswith(".jpg"):
                label_file = f.replace(".jpg", ".txt")
                if label_file in files:
                    valid_pairs.append(f) # ì´ë¯¸ì§€ í‚¤ ì €ì¥
        
        if not valid_pairs:
            print("[Info] ë¼ë²¨ì´ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„° ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print(f"[Info] {len(valid_pairs)}ê°œì˜ ìœ íš¨í•œ ë°ì´í„° ìŒ(ì´ë¯¸ì§€+ë¼ë²¨)ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        # 3. Train/Val ë¶„í•  (8:2)
        random.seed(42)
        random.shuffle(valid_pairs)
        split_idx = int(len(valid_pairs) * 0.8)
        train_files = valid_pairs[:split_idx]
        val_files = valid_pairs[split_idx:]
        
        splits = [("train", train_files), ("valid", val_files)]
        
        # 4. ë‹¤ìš´ë¡œë“œ ë° ì´ë™
        count = 0
        for split_name, file_list in splits:
            img_dir = os.path.join(dataset_dir, split_name, "images")
            lbl_dir = os.path.join(dataset_dir, split_name, "labels")
            
            os.makedirs(img_dir, exist_ok=True)
            os.makedirs(lbl_dir, exist_ok=True)
            
            for img_key in file_list:
                lbl_key = img_key.replace(".jpg", ".txt")
                filename = os.path.basename(img_key)
                lbl_filename = os.path.basename(lbl_key)
                
                # ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥í•˜ì§€ë§Œ, ì—…ë°ì´íŠ¸ ê³ ë ¤í•˜ì—¬ ë®ì–´ì“°ê¸° or check)
                local_img_path = os.path.join(img_dir, filename)
                local_lbl_path = os.path.join(lbl_dir, lbl_filename)
                
                if not os.path.exists(local_img_path):
                    s3.download_file(bucket_name, img_key, local_img_path)
                    s3.download_file(bucket_name, lbl_key, local_lbl_path)
                    count += 1
                    
        if count > 0:
            print(f"[Info] S3ì—ì„œ {count}ê°œì˜ ë°ì´í„° ìŒì„ {dataset_dir}ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
            
            # [Auto Class Detection] ìƒˆë¡œìš´ í´ë˜ìŠ¤ ID ìë™ ê°ì§€ ë° data.yaml ì—…ë°ì´íŠ¸
            update_data_yaml_with_new_classes(dataset_dir)
            
    except Exception as e:
        print(f"[Warning] S3 ë°ì´í„° ë³‘í•© ì‹¤íŒ¨: {e}")


def update_data_yaml_with_new_classes(dataset_dir):
    """
    ë¼ë²¨ íŒŒì¼ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ ìƒˆë¡œìš´ class_idë¥¼ ê°ì§€í•˜ê³  data.yamlì„ ìë™ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    import yaml
    
    data_yaml_path = os.path.join(dataset_dir, "data.yaml")
    
    # 1. ê¸°ì¡´ data.yaml ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(data_yaml_path):
        with open(data_yaml_path, 'r', encoding='utf-8') as f:
            data_config = yaml.safe_load(f)
    else:
        data_config = {'names': {}, 'path': dataset_dir, 'train': 'train/images', 'val': 'valid/images'}
    
    existing_classes = data_config.get('names', {})
    if isinstance(existing_classes, list):
        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        existing_classes = {i: name for i, name in enumerate(existing_classes)}
    
    # 2. ë¼ë²¨ íŒŒì¼ë“¤ì—ì„œ class_id ìˆ˜ì§‘
    found_class_ids = set()
    for split in ['train', 'valid']:
        labels_dir = os.path.join(dataset_dir, split, 'labels')
        if not os.path.exists(labels_dir):
            continue
        
        for label_file in os.listdir(labels_dir):
            if not label_file.endswith('.txt'):
                continue
            
            label_path = os.path.join(labels_dir, label_file)
            try:
                with open(label_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if parts:
                            class_id = int(parts[0])
                            found_class_ids.add(class_id)
            except Exception:
                continue
    
    # 3. ìƒˆë¡œìš´ class_id ê°ì§€ ë° ì¶”ê°€
    new_classes_added = False
    for class_id in found_class_ids:
        if class_id not in existing_classes:
            # ìƒˆ í´ë˜ìŠ¤ ë°œê²¬! ì„ì‹œ ì´ë¦„ìœ¼ë¡œ ì¶”ê°€
            new_class_name = f"class_{class_id}"
            existing_classes[class_id] = new_class_name
            print(f"[Auto Class] ìƒˆ í´ë˜ìŠ¤ ë°œê²¬: {class_id} -> '{new_class_name}' (data.yamlì— ì¶”ê°€ë¨)")
            new_classes_added = True
    
    # 4. data.yaml ì—…ë°ì´íŠ¸
    if new_classes_added:
        data_config['names'] = existing_classes
        with open(data_yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data_config, f, allow_unicode=True, default_flow_style=False)
        print(f"[Auto Class] data.yaml ì—…ë°ì´íŠ¸ ì™„ë£Œ: {data_yaml_path}")
        print(f"[Warning] ìƒˆ í´ë˜ìŠ¤ëª…ì´ 'class_X'ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ë¯¸ìˆëŠ” ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”!")

# =============================================================================
# 2. ì´ˆê¸° ëª¨ë¸ ì •ë°€ë„ ì¸¡ì • (Baseline)
# =============================================================================
def evaluate_baseline():
    print("\n" + "="*50)
    print("[Step 2] ì´ˆê¸° ëª¨ë¸(Baseline) ì •ë°€ë„ ì¸¡ì •...")
    print("="*50)
    
    if data_yaml_path is None:
        print("[Error] ë¨¼ì € ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”")
        return None
    
    # ì‚¬ì „í•™ìŠµ YOLO ëª¨ë¸ ë¡œë“œ (Fine-tuning ì „)
    model = YOLO(BASE_MODEL)
    
    print(f"[Info] ê¸°ë³¸ ëª¨ë¸({BASE_MODEL})ë¡œ í‰ê°€ ì¤‘...")
    metrics = model.val(data=data_yaml_path, split='val')
    
    map50 = metrics.box.map50
    map50_95 = metrics.box.map
    
    print("\n" + "="*40)
    print(f"ğŸ¯ ì´ˆê¸° ëª¨ë¸ ì •ë°€ë„(Baseline):")
    print(f"   mAP50:    {map50:.4f}")
    print(f"   mAP50-95: {map50_95:.4f}")
    print("="*40 + "\n")
    
    return {"map50": map50, "map50_95": map50_95}

# =============================================================================
# 3. ëª¨ë¸ í•™ìŠµ
# =============================================================================
def train_model(epochs=50):
    print("\n" + "="*50)
    print(f"[Step 3] ëª¨ë¸ í•™ìŠµ ì‹œì‘ ({epochs} epochs)...")
    print("="*50)
    
    if data_yaml_path is None:
        print("[Error] ë¨¼ì € ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”")
        return None
    
    model = YOLO(BASE_MODEL)
    
    results = model.train(
        data=data_yaml_path,
        epochs=epochs,
        imgsz=640,
        device=0,  # GPU ì‚¬ìš©
        project=OUTPUT_DIR,
        name="run",
        exist_ok=True
    )
    
    # best.pt ë³µì‚¬
    best_model_path = os.path.join(OUTPUT_DIR, "run", "weights", "best.pt")
    if os.path.exists(best_model_path):
        os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)
        import shutil
        shutil.copy(best_model_path, SAVE_PATH)
        print(f"[âœ“] ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {SAVE_PATH}")
    
    return results

# =============================================================================
# 4. ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸
# =============================================================================
def evaluate_final():
    print("\n" + "="*50)
    print("[Step 4] ìµœì¢… ëª¨ë¸ ì •ë°€ë„ ì¸¡ì •...")
    print("="*50)
    
    if not os.path.exists(SAVE_PATH):
        print(f"[Error] í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {SAVE_PATH}")
        print("ë¨¼ì € --mode train ìœ¼ë¡œ í•™ìŠµì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None
    
    if data_yaml_path is None:
        print("[Error] ë¨¼ì € ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”")
        return None
    
    # í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    model = YOLO(SAVE_PATH)
    
    print(f"[Info] í•™ìŠµëœ ëª¨ë¸({SAVE_PATH})ë¡œ í‰ê°€ ì¤‘...")
    metrics = model.val(data=data_yaml_path, split='test')
    
    map50 = metrics.box.map50
    map50_95 = metrics.box.map
    
    print("\n" + "="*40)
    print(f"ğŸ¯ ìµœì¢… ëª¨ë¸ ì •ë°€ë„(Final):")
    print(f"   mAP50:    {map50:.4f}")
    print(f"   mAP50-95: {map50_95:.4f}")
    print("="*40 + "\n")
    
    return {"map50": map50, "map50_95": map50_95}

# =============================================================================
# Main
# =============================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="YOLOv8 Dashboard Training Script")
    parser.add_argument("--mode", type=str, default="all",
                        choices=["baseline", "train", "test", "all"],
                        help="ì‹¤í–‰ ëª¨ë“œ: baseline(ì´ˆê¸°), train(í•™ìŠµ), test(í…ŒìŠ¤íŠ¸), all(ì „ì²´)")
    parser.add_argument("--epochs", type=int, default=50,
                        help="í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸ê°’: 50)")
    
    args = parser.parse_args()
    
    print(f"\nğŸš€ Dashboard Training Script ì‹œì‘ (mode={args.mode}, epochs={args.epochs})")
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ëª¨ë“  ëª¨ë“œì—ì„œ í•„ìš”)
    download_data()
    
    if args.mode == "baseline":
        evaluate_baseline()
    
    elif args.mode == "train":
        train_model(epochs=args.epochs)
    
    elif args.mode == "test":
        evaluate_final()
    
    elif args.mode == "all":
        baseline = evaluate_baseline()
        train_model(epochs=args.epochs)
        final = evaluate_final()
        
        if baseline and final:
            print("\n" + "="*50)
            print("ğŸ“Š ì •ë°€ë„ ë¹„êµ (mAP50)")
            print("="*50)
            print(f"   ì´ˆê¸° ëª¨ë¸(Baseline): {baseline['map50']:.4f}")
            print(f"   ìµœì¢… ëª¨ë¸(Final):    {final['map50']:.4f}")
            print(f"   í–¥ìƒë„:              +{(final['map50'] - baseline['map50'])*100:.2f}%")
            print("="*50 + "\n")
    
    print("âœ… ì™„ë£Œ!")