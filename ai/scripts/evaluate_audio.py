# ai/scripts/evaluate_audio.py
"""
AST ì˜¤ë””ì˜¤ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë„êµ¬ (Audio Evaluator)

[ì—­í• ]
1. ëª¨ë¸ ê²€ì¦: í•™ìŠµ ì™„ë£Œëœ AST(Audio Spectrogram Transformer) ëª¨ë¸ì˜ ë¶„ë¥˜ ì •í™•ë„(Accuracy)ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
2. ì™¸ë¶€ ë°ì´í„° í…ŒìŠ¤íŠ¸: í•™ìŠµ ë°ì´í„°ì…‹ì´ ì•„ë‹Œ ìƒˆë¡œìš´ í˜„ì¥ ë…¹ìŒ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.
3. ë¦¬í¬íŠ¸ ìƒì„±: í´ë˜ìŠ¤ë³„ ì •í™•ë„ì™€ ì „ì²´ ì—ëŸ¬ìœ¨ì„ ìš”ì•½í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

[ì‚¬ìš©ë²•]
python ai/scripts/evaluate_audio.py

[ì£¼ìš” ì„¤ì •]
- EVAL_DATA_PATHS: í‰ê°€í•˜ê³  ì‹¶ì€ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆëŠ” í´ë” ëª©ë¡
- MODEL_PATH: í‰ê°€ ëŒ€ìƒ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ (ai/weights/audio/best_ast_model)
"""
import os
import torch
import numpy as np
import evaluate
from transformers import ASTForAudioClassification, ASTFeatureExtractor, Trainer, TrainingArguments
from datasets import Dataset, Audio

# -----------------------------------------------------------------------------
# [ì„¤ì •] í‰ê°€í•  ë°ì´í„° ì†ŒìŠ¤ ê²½ë¡œ
# -----------------------------------------------------------------------------
EVAL_DATA_PATHS = [
    "./ai/data/ast/test"  # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ì…‹ ê²½ë¡œë¡œ ìˆ˜ì •
]

MODEL_PATH = "./ai/weights/audio/best_ast_model"

# [ì„¤ì •] ë¼ë²¨ ë§µí•‘ ê·œì¹™ (í•™ìŠµ ë•Œì™€ ë™ì¼í•˜ê²Œ ë§ì¶°ì•¼ í•¨)
LABEL_MAP = {
    "benz_normal": "Normal",
    "audi_normal": "Normal",
    "ì •ìƒ": "Normal",
    
    "Knocking": "Engine_Knocking",
    "Misfire": "Engine_Misfire",
    "Belt": "Belt_Issue",
    "ì†ŒìŒ": "Abnormal_Noise"
}

# -----------------------------------------------------------------------------
# 1. ëª¨ë¸ ë° ì„¤ì • ë¡œë“œ
# -----------------------------------------------------------------------------
if not os.path.exists(MODEL_PATH):
    print(f"[Error] í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
    print("ë¨¼ì € train_audio.pyë¥¼ ì‹¤í–‰í•´ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
    exit()

print(f"[Info] ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤: {MODEL_PATH}")
model = ASTForAudioClassification.from_pretrained(MODEL_PATH)
feature_extractor = ASTFeatureExtractor.from_pretrained(MODEL_PATH)

# ë¼ë²¨ ì •ë³´ ë³µì›
id2label = model.config.id2label
label2id = model.config.label2id
print(f"[Info] í•™ìŠµëœ í´ë˜ìŠ¤ ëª©ë¡: {list(label2id.keys())}")

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# -----------------------------------------------------------------------------
data_list = []

for base_path in EVAL_DATA_PATHS:
    if not os.path.exists(base_path):
        print(f"[Warning] ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_path}")
        continue
        
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.lower().endswith('.wav'):
                folder_name = os.path.basename(root)
                label = LABEL_MAP.get(folder_name, folder_name)
                
                # í•™ìŠµëœ ë¼ë²¨ì— ì—†ëŠ” ìƒˆë¡œìš´ ë¼ë²¨ì´ ë“¤ì–´ì˜¤ë©´ ê²½ê³ 
                if label not in label2id:
                    print(f"[Warning] í•™ìŠµë˜ì§€ ì•Šì€ ë¼ë²¨ ë°œê²¬: {label} (ë¬´ì‹œë¨)")
                    continue
                    
                full_path = os.path.join(root, file)
                data_list.append({"audio": full_path, "label": label})

print(f"[Info] ì´ {len(data_list)}ê°œì˜ í‰ê°€ìš© íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

if len(data_list) == 0:
    print("[Error] í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    print("EVAL_DATA_PATHS ë¦¬ìŠ¤íŠ¸ì— ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    exit()

# Dataset ìƒì„±
eval_ds = Dataset.from_list(data_list).cast_column("audio", Audio(sampling_rate=16000))

def preprocess_function(examples):
    audio_arrays = [x["array"] for x in examples["audio"]]
    inputs = feature_extractor(audio_arrays, sampling_rate=16000, return_tensors="pt", padding="max_length")
    return inputs

print("[Info] ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
eval_dataset = eval_ds.map(preprocess_function, batched=True)

# -----------------------------------------------------------------------------
# 3. í‰ê°€ ì‹¤í–‰
# -----------------------------------------------------------------------------
def compute_metrics(eval_pred):
    accuracy_metric = evaluate.load("accuracy")
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return accuracy_metric.compute(predictions=predictions, references=labels)

# í‰ê°€ìš© Trainer ì„¤ì • (í•™ìŠµì€ ì•ˆ í•¨)
training_args = TrainingArguments(
    output_dir="./Ai/runs/eval_temp",
    per_device_eval_batch_size=8,
    push_to_hub=False,
)

trainer = Trainer(
    model=model,
    args=training_args,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
)

print("[Info] í‰ê°€ ì‹œì‘...")
metrics = trainer.evaluate()

print("\n" + "="*30)
print(f"ğŸ¯ ìµœì¢… ì •í™•ë„(Accuracy): {metrics['eval_accuracy']:.4f}")
print("="*30 + "\n")
