# ai/scripts/sync_active_learning.py
"""
LLM í‹°ì²˜ ê¸°ë°˜ Active Learning ë°ì´í„° ë™ê¸°í™” ë„êµ¬ (Active Learning Synchronizer)

[ì—­í• ]
1. LLM êµì • ë°ì´í„° ìˆ˜ì§‘: ML ëª¨ë¸ì´ í‹€ë ¸ê±°ë‚˜ ëª¨í˜¸í–ˆë˜ ì‚¬ë¡€(Confidence < 0.9) ì¤‘, LLM(Teacher)íŒ€ì´ ì •ë‹µì„ íŒë³„í•˜ì—¬ S3ì— ì €ì¥í•œ ë°ì´í„°(Image + JSON)ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
2. í•™ìŠµì…‹ ìë™ ë³€í™˜: LLMì´ ë‚´ë¦° ì •ë‹µ(JSON)ì„ YOLO í‘œì¤€ í¬ë§·(.txt)ìœ¼ë¡œ ìë™ ë³€í™˜í•©ë‹ˆë‹¤.
3. ë°ì´í„°ì…‹ ë³‘í•©: ë³€í™˜ëœ ë°ì´í„°ì™€ ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ `ai/data/{domain}/retrain` ë””ë ‰í† ë¦¬ì— ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

[ì‚¬ìš©ë²•]
python ai/scripts/sync_active_learning.py --domain tire --limit 100
"""
import os
import json
import boto3
import argparse
import httpx
from pathlib import Path

# =============================================================================
# [Configuration] 
# =============================================================================
BASE_DIR = Path(__file__).parent.parent  # ai/
S3_BUCKET = os.getenv("S3_BUCKET_NAME", "car-sentry-data")

# ë„ë©”ì¸ë³„ í´ë˜ìŠ¤ ë§¤í•‘ (ì‹¤ì œ ëª¨ë¸ì˜ names ë¦¬ìŠ¤íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
DOMAIN_CLASSES = {
    "dashboard": ['Anti Lock Braking System', 'Braking System Issue', 'Charging System Issue', 'Check Engine', 'Electronic Stability Problem -ESP-', 'Engine Overheating Warning Light', 'Low Engine Oil Warning Light', 'Low Tire Pressure Warning Light', 'Master warning light', 'SRS-Airbag'],
    "tire": ["normal", "cracked", "worn", "flat", "bulge", "uneven"], # ë¯¸ë˜ í™•ì¥ì„±(ë°ì´í„° ìˆ˜ì§‘) ê³ ë ¤
    "engine": [
        "Inverter_Coolant_Reservoir", "Battery", "Radiator_Cap", "Windshield_Wiper_Fluid", "Fuse_Box",
        "Power_Steering_Reservoir", "Brake_Fluid", "Engine_Oil_Fill_Cap", "Engine_Oil_Dip_Stick", "Air_Filter_Cover",
        "ABS_Unit", "Alternator", "Engine_Coolant_Reservoir", "Radiator", "Air_Filter", "Engine_Cover",
        "Cold_Air_Intake", "Clutch_Fluid_Reservoir", "Transmission_Oil_Dip_Stick", "Intercooler_Coolant_Reservoir",
        "Oil_Filter_Housing", "ATF_Oil_Reservoir", "Cabin_Air_Filter_Housing", "Secondary_Coolant_Reservoir",
        "Electric_Motor", "Oil_Filter"
    ],
    "exterior": ["dent", "scratch", "crack", "glass_shatter", "lamp_broken", "tire_flat"], # CarDD (íŒŒì†)
    "audio": ["Normal", "Engine_Knocking", "Engine_Misfire", "Belt_Issue", "Abnormal_Noise", "Brake_Squeal", "Suspension_Clunk", "Exhaust_Leak", "Wheel_Bearing_Hum"] # ì„œë¹„ìŠ¤ í‚¤ì›Œë“œ ì¤‘ì‹¬
}
async def download_file(s3_url, target_path):
    """S3 URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ì— ì €ì¥"""
    # boto3ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì•ˆì •ì ì„ (ì¸ì¦ ë¬¸ì œ)
    s3 = boto3.client('s3')
    bucket_name = S3_BUCKET
    
    # s3://bucket/key -> key ì¶”ì¶œ
    if s3_url.startswith(f"s3://{bucket_name}/"):
        key = s3_url.replace(f"s3://{bucket_name}/", "")
    else:
        # HTTP URLì¸ ê²½ìš° (Presigned URL ë“±)
        async with httpx.AsyncClient() as client:
            try:
                response = await client.get(s3_url)
                response.raise_for_status()
                with open(target_path, "wb") as f:
                    f.write(response.content)
                return True
            except Exception as e:
                print(f"      [Error] HTTP ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False

    try:
        s3.download_file(bucket_name, key, str(target_path))
        return True
    except Exception as e:
        print(f"      [Error] S3 ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

async def sync_data(domain, limit):
    print(f"\n[Active Learning] {domain.upper()} ë„ë©”ì¸ ë°ì´í„° ë™ê¸°í™” ì‹œì‘ (ìµœëŒ€ {limit}ê°œ)...")
    
    # 1. S3 ì—°ê²°
    s3 = boto3.client('s3')
    bucket_name = S3_BUCKET
    
    # 2. ì‚¬ìš©ì ì œì•ˆ S3 êµ¬ì¡°ì— ë§ì¶˜ ê²½ë¡œ ì„¤ì •
    if domain == "audio":
        prefix = "dataset/llm_confirmed/audio/"
    else:
        prefix = f"dataset/llm_confirmed/visual/{domain}/"
        
    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    except Exception as e:
        print(f"[Error] S3 ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        return

    if 'Contents' not in response:
        print(f"[Info] ìƒˆë¡œìš´ ì •ë‹µì§€(JSON)ê°€ ì—†ìŠµë‹ˆë‹¤. (Prefix: {prefix})")
        return

    json_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.json')]
    print(f"[Info] {len(json_files)}ê°œì˜ ì •ë‹µì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

    # [ìˆ˜ì •] ë””ë ‰í† ë¦¬ëŠ” ì‹¤ì œ íŒŒì¼ ì €ì¥ ì§ì „ì— ìƒì„±í•˜ì—¬ ë¹ˆ í´ë” ë°©ì§€
    target_data_dir = BASE_DIR / "data" / domain / "retrain"
    target_img_dir = target_data_dir / "images"
    target_lbl_dir = target_data_dir / "labels"
    target_wav_dir = target_data_dir / "wavs"

    class_list = DOMAIN_CLASSES.get(domain, [])
    success_count = 0
    new_classes_found = set()
    
    # COCO ë°ì´í„° êµ¬ì¡° (exterior ì „ìš©)
    coco_data = {
        "images": [],
        "annotations": [],
        "categories": [{"id": i, "name": name} for i, name in enumerate(class_list)]
    }
    ann_id_counter = 1
    img_id_counter = 1

    for key in json_files[:limit]:
        file_id = os.path.basename(key).split('.')[0]
        
        # JSON ë‹¤ìš´ë¡œë“œ
        try:
            obj = s3.get_object(Bucket=bucket_name, Key=key)
            data = json.loads(obj['Body'].read().decode('utf-8'))
        except Exception as e:
            print(f"  - [Error] JSON ë¡œë“œ ì‹¤íŒ¨ ({key}): {e}")
            continue
        
        # ì›ë³¸ íŒŒì¼ URL ì°¾ê¸°
        source_url = data.get("source_url")
        if not source_url:
            print(f"  - [Skip] source_url ì •ë³´ ì—†ìŒ ({file_id})")
            continue

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ì§€ ë˜ëŠ” ì˜¤ë””ì˜¤)
        ext = os.path.splitext(source_url)[1] or ('.wav' if domain == 'audio' else '.jpg')
        sub_dir = 'wavs' if domain == 'audio' else 'images'
        file_path = target_data_dir / sub_dir / f"{file_id}{ext}"
        
        if not file_path.exists():
            file_path.parent.mkdir(parents=True, exist_ok=True) # íŒŒì¼ ì €ì¥ ì§ì „ í´ë” ìƒì„±
            if not await download_file(source_url, file_path):
                continue

        # ë¼ë²¨ ì €ì¥ (YOLO vs AST vs COCO vs Classification)
        if domain == "audio":
            label = data.get("label", "NORMAL")
            if label not in class_list:
                new_classes_found.add(label)
            with open(label_file, "a", encoding="utf-8") as f:
                f.write(f"{file_id}{ext},{label}\n")
        elif domain == "exterior":
            # COCO í¬ë§· ë°ì´í„° ìˆ˜ì§‘ (ìƒëµ - ì´ì „ê³¼ ë™ì¼)
            coco_data["images"].append({
                "id": img_id_counter,
                "width": 1024,
                "height": 1024,
                "file_name": f"{file_id}{ext}"
            })
            labels = data.get("labels", [])
            for lbl in labels:
                cls_name = lbl.get("class")
                if cls_name in class_list:
                    cls_id = class_list.index(cls_name)
                    bbox = lbl.get("bbox", [0.5, 0.5, 0.1, 0.1])
                    cw, ch = 1024, 1024
                    x = (bbox[0] - bbox[2]/2) * cw
                    y = (bbox[1] - bbox[3]/2) * ch
                    w = bbox[2] * cw
                    h = bbox[3] * ch
                    coco_data["annotations"].append({
                        "id": ann_id_counter,
                        "image_id": img_id_counter,
                        "category_id": cls_id,
                        "bbox": [x, y, w, h],
                        "area": w * h,
                        "iscrowd": 0
                    })
                    ann_id_counter += 1
                else:
                    new_classes_found.add(cls_name)
            img_id_counter += 1
        elif domain == "tire":
            # ë¶„ë¥˜(Classification) ëª¨ë¸ìš©: í´ë”ë³„ ìë™ ë¶„ë¥˜
            # LLMì´ íŒë‹¨í•œ critical_issues ì¤‘ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ í´ë˜ìŠ¤ë¡œ ì„ íƒ (ì—†ìœ¼ë©´ normal)
            issues = data.get("critical_issues", [])
            target_class = "normal"
            if issues:
                # class_listì— ìˆëŠ” ê²ƒ ì¤‘ ê°€ì¥ ìš°ì„ ìˆœìœ„ ë†’ì€ ê²ƒ ì„ íƒ
                for issue in issues:
                    if issue in class_list:
                        target_class = issue
                        break
                if target_class == "normal": # class_listì— ì—†ëŠ” ìƒˆë¡œìš´ ì´ìŠˆ
                    new_classes_found.add(issues[0])
            
            # ì´ë¯¸ì§€ë¥¼ í•´ë‹¹ í´ë˜ìŠ¤ í´ë”ë¡œ ì´ë™/ì €ì¥
            class_dir = target_data_dir / target_class
            class_dir.mkdir(parents=True, exist_ok=True)
            
            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ í´ë˜ìŠ¤ í´ë”ë¡œ ì´ë™ (ë˜ëŠ” ì²˜ìŒë¶€í„° ê²½ë¡œ ì§€ì •)
            final_file_path = class_dir / f"{file_id}{ext}"
            if file_path.exists() and not final_file_path.exists():
                os.replace(file_path, final_file_path)
            
            print(f"  - [âœ“] {file_id} ({target_class}) ë¶„ë¥˜ ì™„ë£Œ")
        else:
            # YOLO txt í¬ë§· ìƒì„± (Detection ëª¨ë¸ìš©)
            labels = data.get("labels", [])
            yolo_lines = []
            for lbl in labels:
                cls_name = lbl.get("class")
                if cls_name in class_list:
                    cls_id = class_list.index(cls_name)
                    bbox = lbl.get("bbox", [0.5, 0.5, 0.1, 0.1])
                    yolo_lines.append(f"{cls_id} {' '.join(map(str, bbox))}")
                else:
                    new_classes_found.add(cls_name)
            
            if yolo_lines:
                with open(target_lbl_dir / f"{file_id}.txt", "w") as f:
                    f.write("\n".join(yolo_lines))
        
        if domain != "tire": # íƒ€ì´ì–´ëŠ” ìœ„ì—ì„œ ë³„ë„ ì¶œë ¥
            print(f"  - [âœ“] {file_id} ë™ê¸°í™” ì™„ë£Œ")
        success_count += 1

    # ì™¸ê´€(exterior) ë„ë©”ì¸ì¸ ê²½ìš° ìµœì¢… COCO JSON ì €ì¥
    if domain == "exterior":
        coco_json_path = target_data_dir / "retrain_coco.json"
        with open(coco_json_path, "w", encoding="utf-8") as f:
            json.dump(coco_data, f, ensure_ascii=False, indent=2)
        print(f"[Info] COCO í†µí•© ì¥ë¶€ ì €ì¥ ì™„ë£Œ: {coco_json_path}")

    print(f"\n[âœ“] ì´ {success_count}ê°œì˜ ë°ì´í„°ê°€ ë¡œì»¬ 'retrain' í´ë”ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if new_classes_found:
        print("\n[ğŸš¨ New Classes Discovered]")
        for nc in new_classes_found:
            print(f"  - {nc}")

    # 4. ë¹ˆ í´ë” ì •ë¦¬ (ì‹¤ìˆ˜ë¡œ ìƒì„±ëœ ê²½ìš°)
    for root, dirs, files in os.walk(target_data_dir, topdown=False):
        for name in dirs:
            dir_path = os.path.join(root, name)
            if not os.listdir(dir_path): # ë¹„ì–´ìˆìœ¼ë©´
                os.rmdir(dir_path)

if __name__ == "__main__":
    import asyncio
    parser = argparse.ArgumentParser(description="LLM-Guided Active Learning Sync")
    parser.add_argument("--domain", type=str, required=True, 
                        choices=["engine", "dashboard", "tire", "exterior", "audio"])
    parser.add_argument("--limit", type=int, default=100)
    args = parser.parse_args()
    
    asyncio.run(sync_data(args.domain, args.limit))
