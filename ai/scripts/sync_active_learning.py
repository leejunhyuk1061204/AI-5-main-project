# ai/scripts/sync_active_learning.py
"""
LLM í‹°ì²˜ ê¸°ë°˜ Active Learning ë°ì´í„° ë™ê¸°í™” ë„êµ¬ (Active Learning Synchronizer)

[ì—­í• ]
1. LLM êµì • ë°ì´í„° ìˆ˜ì§‘: ML ëª¨ë¸ì´ í‹€ë ¸ê±°ë‚˜ ëª¨í˜¸í–ˆë˜ ì‚¬ë¡€(Confidence < 0.9) ì¤‘, LLM(Teacher)íŒ€ì´ ì •ë‹µì„ íŒë³„í•˜ì—¬ S3ì— ì €ì¥í•œ ë°ì´í„°(Image + JSON)ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
2. í•™ìŠµì…‹ ìë™ ë³€í™˜: LLMì´ ë‚´ë¦° ì •ë‹µ(JSON)ì„ YOLO í‘œì¤€ í¬ë§·(.txt)ìœ¼ë¡œ ìë™ ë³€í™˜í•©ë‹ˆë‹¤.
3. ë°ì´í„°ì…‹ ë³‘í•©: ë³€í™˜ëœ ë°ì´í„°ì™€ ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ `ai/data/{domain}/retrain` ë””ë ‰í† ë¦¬ì— ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

[ì‚¬ìš©ë²•]
python ai/scripts/sync_active_learning.py --domain tire --limit 100
"""
import os
import json
import boto3
import argparse
import httpx
from pathlib import Path

# =============================================================================
# [Configuration] 
# =============================================================================
BASE_DIR = Path(__file__).parent.parent  # ai/
S3_BUCKET = os.getenv("S3_BUCKET_NAME", "car-sentry-data")

# ë„ë©”ì¸ë³„ í´ë˜ìŠ¤ ë§¤í•‘ (ì‹¤ì œ ëª¨ë¸ì˜ names ë¦¬ìŠ¤íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
DOMAIN_CLASSES = {
    "dashboard": ["ABS", "Brake", "Battery", "Engine", "ESP", "Overheating", "Oil", "Tire", "Master", "Airbag"],
    "tire": ["normal", "cracked", "worn", "flat", "bulge", "uneven"], # uneven ì¶”ê°€
    "engine": ["Battery", "Engine_Cover", "Oil_Cap", "Coolant_Reservoir", "Fuse_Box"], # ì˜ˆì‹œ
    "exterior": ["dent", "scratch", "crack", "glass_shatter", "lamp_broken", "tire_flat"],
    "audio": ["ENG_IDLE", "ENG_KNOCKING", "BRAKE_SQUEAL", "SUSP_CLUNK"] # ASTìš© ì˜ˆì‹œ
}

async def download_file(s3_url, target_path):
    """S3 URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ì— ì €ì¥"""
    # boto3ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì•ˆì •ì ì„ (ì¸ì¦ ë¬¸ì œ)
    s3 = boto3.client('s3')
    bucket_name = S3_BUCKET
    
    # s3://bucket/key -> key ì¶”ì¶œ
    if s3_url.startswith(f"s3://{bucket_name}/"):
        key = s3_url.replace(f"s3://{bucket_name}/", "")
    else:
        # HTTP URLì¸ ê²½ìš° (Presigned URL ë“±)
        async with httpx.AsyncClient() as client:
            try:
                response = await client.get(s3_url)
                response.raise_for_status()
                with open(target_path, "wb") as f:
                    f.write(response.content)
                return True
            except Exception as e:
                print(f"      [Error] HTTP ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False

    try:
        s3.download_file(bucket_name, key, str(target_path))
        return True
    except Exception as e:
        print(f"      [Error] S3 ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

async def sync_data(domain, limit):
    print(f"\n[Active Learning] {domain.upper()} ë„ë©”ì¸ ë°ì´í„° ë™ê¸°í™” ì‹œì‘ (ìµœëŒ€ {limit}ê°œ)...")
    
    # 1. S3 ì—°ê²°
    s3 = boto3.client('s3')
    bucket_name = S3_BUCKET
    
    # 2. ì‚¬ìš©ì ì œì•ˆ S3 êµ¬ì¡°ì— ë§ì¶˜ ê²½ë¡œ ì„¤ì •
    if domain == "audio":
        prefix = "dataset/llm_confirmed/audio/"
    else:
        prefix = f"dataset/llm_confirmed/visual/{domain}/"
        
    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    except Exception as e:
        print(f"[Error] S3 ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        return

    if 'Contents' not in response:
        print(f"[Info] ìƒˆë¡œìš´ ì •ë‹µì§€(JSON)ê°€ ì—†ìŠµë‹ˆë‹¤. (Prefix: {prefix})")
        return

    json_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.json')]
    print(f"[Info] {len(json_files)}ê°œì˜ ì •ë‹µì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

    # 3. ë¡œì»¬ ë””ë ‰í† ë¦¬ ì¤€ë¹„
    target_data_dir = BASE_DIR / "data" / domain / "retrain" # retrain í´ë” ì‚¬ìš©
    if domain == "audio":
        target_wav_dir = target_data_dir / "wavs"
        target_wav_dir.mkdir(parents=True, exist_ok=True)
        label_file = target_data_dir / "labels.csv"
    else:
        target_img_dir = target_data_dir / "images"
        target_lbl_dir = target_data_dir / "labels"
        target_img_dir.mkdir(parents=True, exist_ok=True)
        target_lbl_dir.mkdir(parents=True, exist_ok=True)

    class_list = DOMAIN_CLASSES.get(domain, [])
    success_count = 0
    new_classes_found = set()

    for key in json_files[:limit]:
        file_id = os.path.basename(key).split('.')[0]
        
        # JSON ë‹¤ìš´ë¡œë“œ
        try:
            obj = s3.get_object(Bucket=bucket_name, Key=key)
            data = json.loads(obj['Body'].read().decode('utf-8'))
        except Exception as e:
            print(f"  - [Error] JSON ë¡œë“œ ì‹¤íŒ¨ ({key}): {e}")
            continue
        
        # ì›ë³¸ íŒŒì¼ URL ì°¾ê¸°
        source_url = data.get("source_url")
        if not source_url:
            print(f"  - [Skip] source_url ì •ë³´ ì—†ìŒ ({file_id})")
            continue

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ì§€ ë˜ëŠ” ì˜¤ë””ì˜¤)
        ext = os.path.splitext(source_url)[1] or ('.wav' if domain == 'audio' else '.jpg')
        sub_dir = 'wavs' if domain == 'audio' else 'images'
        file_path = target_data_dir / sub_dir / f"{file_id}{ext}"
        
        if not file_path.exists():
            if not await download_file(source_url, file_path):
                continue

        # ë¼ë²¨ ì €ì¥ (YOLO vs AST)
        if domain == "audio":
            label = data.get("label", "NORMAL")
            if label not in class_list:
                new_classes_found.add(label)
            with open(label_file, "a", encoding="utf-8") as f:
                f.write(f"{file_id}{ext},{label}\n")
        else:
            # YOLO txt í¬ë§· ìƒì„±
            labels = data.get("labels", [])
            # íƒ€ì´ì–´ ë§ˆëª¨ë„(pct) í•™ìŠµìš© ë°ì´í„°ëŠ” ë³„ë„ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ì¼ë‹¨ YOLO í´ë˜ìŠ¤ í•™ìŠµ ìœ„ì£¼
            yolo_lines = []
            for lbl in labels:
                cls_name = lbl.get("class")
                if cls_name in class_list:
                    cls_id = class_list.index(cls_name)
                    bbox = lbl.get("bbox", [0.5, 0.5, 0.1, 0.1])
                    yolo_lines.append(f"{cls_id} {' '.join(map(str, bbox))}")
                else:
                    new_classes_found.add(cls_name)
            
            # íƒ€ì´ì–´ ë§ˆëª¨ë„ì˜ ê²½ìš° critical_issuesë¥¼ í´ë˜ìŠ¤ë¡œ í™œìš©
            if domain == "tire" and not yolo_lines:
                issues = data.get("critical_issues", [])
                if issues:
                    for issue in issues:
                        if issue in class_list:
                            cls_id = class_list.index(issue)
                            yolo_lines.append(f"{cls_id} 0.5 0.5 0.8 0.8") # ì „ì²´ ì˜ì—­ ê·¼ì‚¬

            if yolo_lines:
                with open(target_lbl_dir / f"{file_id}.txt", "w") as f:
                    f.write("\n".join(yolo_lines))
        
        print(f"  - [âœ“] {file_id} ë™ê¸°í™” ë° ë³€í™˜ ì™„ë£Œ")
        success_count += 1

    print(f"\n[âœ“] ì´ {success_count}ê°œì˜ ë°ì´í„°ê°€ ë¡œì»¬ 'retrain' í´ë”ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if new_classes_found:
        print("\n[ğŸš¨ New Classes Discovered]")
        for nc in new_classes_found:
            print(f"  - {nc}")

if __name__ == "__main__":
    import asyncio
    parser = argparse.ArgumentParser(description="LLM-Guided Active Learning Sync")
    parser.add_argument("--domain", type=str, required=True, 
                        choices=["engine", "dashboard", "tire", "exterior", "audio"])
    parser.add_argument("--limit", type=int, default=100)
    args = parser.parse_args()
    
    asyncio.run(sync_data(args.domain, args.limit))
