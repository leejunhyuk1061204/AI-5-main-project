# ai/scripts/train_router.py
"""
AI ë¶„ì„ ì¥ë©´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ë„êµ¬ (Router Classification Trainer)

[ì—­í• ]
1. ì¥ë©´ ë¶„ë¥˜ í•™ìŠµ: ì´ë¯¸ì§€ê°€ ì°¨ëŸ‰ì˜ ì–´ëŠ ë¶€ìœ„(ì—”ì§„, ê³„ê¸°íŒ, ì™¸ê´€, íƒ€ì´ì–´)ì¸ì§€ íŒë‹¨í•˜ëŠ” MobileNetV3-Small ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
2. ê²½ëŸ‰í™” ëª¨ë¸: ëª¨ë°”ì¼ ë° ì‹¤ì‹œê°„ í™˜ê²½ì— ìµœì í™”ëœ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
3. ë°ì´í„°ì…‹ ì—°ë™: ai/data/yolo_routerì— êµ¬ì„±ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.

[ì‚¬ìš©ë²•]
1. ë°ì´í„°ì…‹ ìƒì„±: python ai/scripts/create_router_dataset.py
2. ëª¨ë¸ í•™ìŠµ: python ai/scripts/train_router.py --epochs 50
"""

import os
import argparse
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
import shutil

# =============================================================================
# [Configuration]
# =============================================================================
DATA_DIR = "ai/data/yolo_router"
SAVE_PATH = "ai/weights/router/best.pt"
IMG_SIZE = 224
BATCH_SIZE = 32
DEFAULT_EPOCHS = 50
LEARNING_RATE = 0.001

def train_model(epochs=DEFAULT_EPOCHS):
    print("\n" + "="*60)
    print(f"ğŸš€ Router ì¥ë©´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (MobileNetV3-Small)")
    print(f"   Epochs: {epochs}, Batch Size: {BATCH_SIZE}")
    print("="*60)

    # Device ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[Device] Using: {device}")

    # ë°ì´í„° ì „ì²˜ë¦¬
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(IMG_SIZE),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(IMG_SIZE),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    # ë°ì´í„°ì…‹ ë¡œë“œ
    image_datasets = {
        x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])
        for x in ['train', 'val']
    }
    dataloaders = {
        x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
        for x in ['train', 'val']
    }
    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
    class_names = image_datasets['train'].classes
    print(f"[Data] Classes: {class_names}")
    print(f"[Data] Train: {dataset_sizes['train']}, Val: {dataset_sizes['val']}")

    # ëª¨ë¸ ìƒì„± (MobileNetV3-Small)
    try:
        model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)
    except AttributeError:
        # êµ¬ë²„ì „ ë˜ëŠ” ë‹¤ë¥¸ ëª…ì¹­ ëŒ€ì²˜
        print("[Info] MobileNet_V3_Small_Weights not found, trying legacy pretrained=True")
        model = models.mobilenet_v3_small(pretrained=True)
    
    # ì¶œë ¥ì¸µ ìˆ˜ì • (4ê°œ í´ë˜ìŠ¤)
    num_ftrs = model.classifier[-1].in_features
    model.classifier[-1] = nn.Linear(num_ftrs, len(class_names))
    model = model.to(device)

    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # í•™ìŠµ ë£¨í”„
    since = time.time()
    best_acc = 0.0
    best_model_wts = model.state_dict()

    for epoch in range(epochs):
        print(f'\nEpoch {epoch+1}/{epochs}')
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            batch_idx = 0
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
                
                # ë°°ì¹˜ ì§„í–‰ë¥  í‘œì‹œ (ì¶”ê°€ë¨)
                batch_idx += 1
                if batch_idx % 20 == 0:
                    print(f"  [{phase}] Batch {batch_idx}/{len(dataloaders[phase])} Loss: {loss.item():.4f}")

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # Best ëª¨ë¸ ì €ì¥
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = model.state_dict()

    time_elapsed = time.time() - since
    print(f'\n[âœ“] í•™ìŠµ ì™„ë£Œ! ì†Œìš” ì‹œê°„: {time_elapsed // 60:.0f}ë¶„ {time_elapsed % 60:.0f}ì´ˆ')
    print(f'[âœ“] Best Val Acc: {best_acc:4f}')

    # ê°€ì¤‘ì¹˜ ì €ì¥
    os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)
    torch.save(best_model_wts, SAVE_PATH)
    print(f"[âœ“] Best ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {SAVE_PATH}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Router Classification Training")
    parser.add_argument("--epochs", type=int, default=DEFAULT_EPOCHS)
    args = parser.parse_args()
    
    train_model(args.epochs)
