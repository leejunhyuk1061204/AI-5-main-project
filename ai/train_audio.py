import kagglehub
import os
import torch
import librosa
import numpy as np
from transformers import ASTConfig, ASTForAudioClassification, ASTFeatureExtractor, Trainer, TrainingArguments
from datasets import Dataset, Audio
from sklearn.model_selection import train_test_split
import evaluate

# -----------------------------------------------------------------------------
# [ì„¤ì •] ë°ì´í„° ì†ŒìŠ¤ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (í™•ì¥ì„±: ì—¬ê¸°ì— ìƒˆ ê²½ë¡œë§Œ ì¶”ê°€í•˜ë©´ ë¨)
# -----------------------------------------------------------------------------
DATA_SOURCE_PATHS = []

# 1. Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ìë™ ì¶”ê°€)
try:
    kaggle_path = kagglehub.dataset_download("janboubiabderrahim/vehicle-sounds-dataset")
    print(f"[Info] Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {kaggle_path}")
    DATA_SOURCE_PATHS.append(kaggle_path)
except Exception as e:
    print(f"[Warning] Kaggle ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì¸í„°ë„· ì—°ê²° í™•ì¸): {e}")

# 2. ë¡œì»¬ ë°ì´í„° í´ë” (ì˜ˆì‹œ: í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ í›„ ìˆ˜ì •)
# DATA_SOURCE_PATHS.append("C:/Users/301/Documents/MyCarSounds")

print(f"[Info] ì´ {len(DATA_SOURCE_PATHS)}ê°œì˜ ë°ì´í„° ì†ŒìŠ¤ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 3. ì „ì²˜ë¦¬ ì„¤ì • (16kHz ë¦¬ìƒ˜í”Œë§)
# -----------------------------------------------------------------------------
feature_extractor = ASTFeatureExtractor.from_pretrained("MIT/ast-finetuned-audioset-10-10-0.4593")

def preprocess_function(examples):
    audio_arrays = [x["array"] for x in examples["audio"]]
    inputs = feature_extractor(audio_arrays, sampling_rate=16000, return_tensors="pt", padding="max_length")
    return inputs

def compute_metrics(eval_pred):
    accuracy_metric = evaluate.load("accuracy")
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return accuracy_metric.compute(predictions=predictions, references=labels)

# -----------------------------------------------------------------------------
# 4. ë°ì´í„° ë¡œë“œ (Recursive os.walk)
# -----------------------------------------------------------------------------
# [ì„¤ì •] ë¼ë²¨ ë§µí•‘ ê·œì¹™ (í´ë”ëª… -> í•™ìŠµí•  ë¼ë²¨ëª…)
# ì´ ë”•ì…”ë„ˆë¦¬ì— ì—†ëŠ” í´ë”ëª…ì€ ê·¸ëƒ¥ í´ë”ëª… ê·¸ëŒ€ë¡œ ë¼ë²¨ë¡œ ì‚¬ìš©ë¨
LABEL_MAP = {
    # ì˜ˆì‹œ: "í´ë”ì´ë¦„": "í†µí•©ë¼ë²¨"
    "benz_normal": "Normal",
    "audi_normal": "Normal",
    "ì •ìƒ": "Normal",
    
    "Knocking": "Engine_Knocking",
    "Misfire": "Engine_Misfire",
    "Belt": "Belt_Issue",
    "ì†ŒìŒ": "Abnormal_Noise"
}

data_list = []

for base_path in DATA_SOURCE_PATHS:
    if not os.path.exists(base_path):
        continue
        
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.lower().endswith('.wav'):
                # 1. íŒŒì¼ì´ ë“¤ì–´ìˆëŠ” 'ë°”ë¡œ ìœ„ í´ë” ì´ë¦„' ì¶”ì¶œ
                folder_name = os.path.basename(root)
                
                # 2. ë¼ë²¨ ë§µí•‘ ì ìš© (ì—†ìœ¼ë©´ í´ë”ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©)
                label = LABEL_MAP.get(folder_name, folder_name)
                
                full_path = os.path.join(root, file)
                data_list.append({"audio": full_path, "label": label})

print(f"[Info] ì´ {len(data_list)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

if len(data_list) == 0:
    print("[Error] ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

# -----------------------------------------------------------------------------
# 5. ë°ì´í„° ë¶„í•  (7:2:1 -> Train:Test:Valid)
# -----------------------------------------------------------------------------
# ë¼ë²¨ ì¸ì½”ë”© ì¤€ë¹„
labels = list(set([x['label'] for x in data_list]))
label2id = {label: i for i, label in enumerate(labels)}
id2label = {i: label for i, label in enumerate(labels)}

print(f"[Info] ê°ì§€ëœ ë¼ë²¨({len(labels)}ê°œ): {labels}")

# 1ë‹¨ê³„: ì „ì²´ë¥¼ Train(80%) + Rest(20%)ë¡œ ë¶„í•  (Testìš© í™•ë³´)
train_val, test_data = train_test_split(
    data_list, test_size=0.2, stratify=[x['label'] for x in data_list], random_state=42
)

# 2ë‹¨ê³„: Train(80%)ë¥¼ ë‹¤ì‹œ Train(70%) + Valid(10%)ë¡œ ë¶„í• 
# ë‚¨ì€ 80% ì¤‘ì—ì„œ 1/8(12.5%)ì„ ë–¼ì–´ë‚´ë©´ ì „ì²´ì˜ 10%ê°€ ë¨
train_data, val_data = train_test_split(
    train_val, test_size=0.125, stratify=[x['label'] for x in train_val], random_state=42
)

print(f"[Info] ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
print(f" - í•™ìŠµìš©(Train 70%): {len(train_data)}ê°œ")
print(f" - ê²€ì¦ìš©(Valid 10%): {len(val_data)}ê°œ (í•™ìŠµ ì¤‘ ì„±ëŠ¥ ì²´í¬)")
print(f" - í‰ê°€ìš©(Test  20%): {len(test_data)}ê°œ (ìµœì¢… ì±„ì )")

# Dataset ê°ì²´ ìƒì„±
train_ds = Dataset.from_list(train_data).cast_column("audio", Audio(sampling_rate=16000))
val_ds   = Dataset.from_list(val_data).cast_column("audio", Audio(sampling_rate=16000))
test_ds  = Dataset.from_list(test_data).cast_column("audio", Audio(sampling_rate=16000))

# ì „ì²˜ë¦¬ ì ìš©
print("[Info] ë°ì´í„° ì „ì²˜ë¦¬(Audio -> Spectrogram) ì‹œì‘...")
train_dataset = train_ds.map(preprocess_function, batched=True)
eval_dataset  = val_ds.map(preprocess_function, batched=True)
test_dataset  = test_ds.map(preprocess_function, batched=True)

# -----------------------------------------------------------------------------
# 6. ëª¨ë¸ í•™ìŠµ
# -----------------------------------------------------------------------------
model = ASTForAudioClassification.from_pretrained(
    "MIT/ast-finetuned-audioset-10-10-0.4593",
    num_labels=len(labels),
    label2id=label2id,
    id2label=id2label,
    ignore_mismatched_sizes=True
)

training_args = TrainingArguments(
    output_dir="./Ai/runs/audio_model",
    per_device_train_batch_size=8,
    num_train_epochs=10,
    learning_rate=3e-5,
    logging_dir='./logs',
    evaluation_strategy="epoch", # ë§¤ epochë§ˆë‹¤ ê²€ì¦(Valid) ìˆ˜í–‰
    save_strategy="epoch",
    load_best_model_at_end=True, # Valid ì ìˆ˜ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥
    metric_for_best_model="accuracy",
    push_to_hub=False,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,   # ì—¬ê¸°ëŠ” ê²€ì¦ì…‹(10%)
    compute_metrics=compute_metrics,
)

print("AST ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
trainer.train()

# -----------------------------------------------------------------------------
# 7. ìµœì¢… í‰ê°€ ë° ì €ì¥
# -----------------------------------------------------------------------------
print("[Info] ìµœì¢… í…ŒìŠ¤íŠ¸(Test 20%) ìˆ˜í–‰ ì¤‘...")
metrics = trainer.evaluate(test_dataset) # ì—¬ê¸°ëŠ” í…ŒìŠ¤íŠ¸ì…‹(20%)
print(f"ğŸ¯ ìµœì¢… ì •í™•ë„(Accuracy): {metrics['eval_accuracy']:.4f}")

# 7. í•™ìŠµëœ ëª¨ë¸ ì €ì¥ (ì´ê²ƒì´ ìŒì„±íŒ 'best.pt'ê°€ ë©ë‹ˆë‹¤)
model.save_pretrained("./ai/weights/audio/best_ast_model")
feature_extractor.save_pretrained("./ai/weights/audio/best_ast_model") # Feature Extractorë„ ê°™ì´ ì €ì¥
print("í•™ìŠµ ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥ ì™„ë£Œ")